{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷积层的实现\n",
    "\n",
    "## 自定义权值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 3, 4), dtype=float32, numpy=\n",
       "array([[[[ -3.6205294 ,   0.12113128,   3.975155  ,   4.2588205 ],\n",
       "         [ -0.92554164,   2.3715444 ,   4.1500087 ,   6.169531  ],\n",
       "         [ -2.748736  ,  -3.6382902 ,   3.256584  ,   0.64921546]],\n",
       "\n",
       "        [[ -2.1724381 ,  -7.3499985 ,   0.19241051,   0.9158553 ],\n",
       "         [ -0.7582543 ,  -2.3493822 ,  -9.651439  ,  -0.18819858],\n",
       "         [ -4.0487957 ,  -6.104577  ,  -7.7606187 , -15.178026  ]],\n",
       "\n",
       "        [[-13.72019   ,  -4.0969095 ,  -4.2858624 ,   3.6450531 ],\n",
       "         [ -4.384036  ,   2.6716363 ,   7.117439  ,  -3.184749  ],\n",
       "         [  1.1888121 ,   3.345669  ,  13.3670635 ,  -4.0083647 ]]],\n",
       "\n",
       "\n",
       "       [[[ -1.2238516 ,  -4.9339986 ,  -3.3781621 ,  -4.009736  ],\n",
       "         [ -3.3000314 ,   0.08951158,  -3.2791655 ,   4.122613  ],\n",
       "         [ -3.5964067 ,   3.1056929 ,   5.8081746 ,   3.0280197 ]],\n",
       "\n",
       "        [[  0.8647205 ,  -3.25087   ,   1.3345604 ,  -5.885718  ],\n",
       "         [ -5.611656  ,   1.7081407 ,   1.0742087 ,  -0.34089044],\n",
       "         [  2.8555193 ,   6.113435  ,   4.160484  ,  -0.85069263]],\n",
       "\n",
       "        [[  0.8917673 ,  -4.370077  ,  -4.040577  ,  -7.271827  ],\n",
       "         [ -0.63092464,  -6.04351   ,  -1.1102389 ,  -9.256438  ],\n",
       "         [ -1.4764416 ,  -0.07018235,  -5.705756  ,  -1.9626676 ]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "x=tf.random.normal([2,5,5,3]) # 模拟输入3通道，高度为5\n",
    "# 按照[k,k,cin,cout]格式创建W张量， 4个3x3大小的卷积核\n",
    "w=tf.random.normal([3,3,3,4])\n",
    "# 步长为1，padding为0\n",
    "out=tf.nn.conv2d(x,w,strides=1,padding=[[0,0],[0,0],[0,0],[0,0]])\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**padding参数的格式**\n",
    "```python\n",
    " padding=[[0,0],[上,下],[上,下],[0,0],[0,0]]\n",
    "```\n",
    "若上下各填充一个单位即\n",
    "```\n",
    "padding=[[0,0],[1,1],[1,1],[0,0]]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5, 5, 4), dtype=float32, numpy=\n",
       "array([[[[-6.3244872e+00,  2.2933266e-01, -1.5882653e-01,\n",
       "           1.7424980e+00],\n",
       "         [-3.1104689e+00, -2.7524869e+00, -6.7510486e-01,\n",
       "           1.2716680e+00],\n",
       "         [ 6.9353266e+00,  3.7843599e+00, -1.7463094e+00,\n",
       "          -4.9824457e+00],\n",
       "         [-1.4650377e+00, -6.2528509e-01, -1.9418563e+00,\n",
       "           2.2172630e+00],\n",
       "         [-8.3582563e+00, -2.9390628e+00, -4.1312957e-01,\n",
       "          -7.5315547e-01]],\n",
       "\n",
       "        [[-4.7451887e-01, -1.4345539e-01, -6.2943535e+00,\n",
       "          -2.3832414e-01],\n",
       "         [-2.8564706e+00, -2.1109004e+00, -1.8896719e+00,\n",
       "          -1.2391912e+00],\n",
       "         [-2.6193919e+00, -4.5793228e+00,  2.4074903e+00,\n",
       "           1.7983577e+00],\n",
       "         [-4.1318059e+00,  5.6728392e+00,  3.4322548e+00,\n",
       "           2.0427771e+00],\n",
       "         [ 1.2388480e+00, -1.2714338e-01,  1.3406159e+00,\n",
       "           1.0918202e+00]],\n",
       "\n",
       "        [[-5.2072463e+00, -4.1823125e+00, -1.0269697e+00,\n",
       "           4.7673969e+00],\n",
       "         [ 6.6360813e-01,  2.1434245e+00,  2.6848242e+00,\n",
       "          -3.2772574e+00],\n",
       "         [-5.0825560e-01,  7.5790033e+00, -5.2637072e+00,\n",
       "          -1.0053171e+00],\n",
       "         [-6.6214972e+00, -4.7407613e+00,  3.1316662e+00,\n",
       "          -2.3799729e+00],\n",
       "         [-2.6460187e+00, -1.7827058e+00,  1.3895295e+00,\n",
       "           5.7319503e+00]],\n",
       "\n",
       "        [[ 1.7379650e+00, -7.6853147e+00, -1.5106391e+00,\n",
       "          -4.1821828e+00],\n",
       "         [ 5.0903096e+00, -3.3085507e-01, -4.8472948e+00,\n",
       "           1.4145243e+00],\n",
       "         [-1.2571192e+01, -5.0584936e-01,  4.3108091e+00,\n",
       "          -7.0244408e-01],\n",
       "         [ 2.8373535e+00,  3.2134519e+00, -3.0063791e+00,\n",
       "          -3.1414494e-01],\n",
       "         [ 1.1553353e+01,  8.2246721e-02, -3.8150816e+00,\n",
       "           9.8463070e-01]],\n",
       "\n",
       "        [[ 6.3118744e-01,  6.0824208e+00,  3.6265957e+00,\n",
       "           6.1483383e-03],\n",
       "         [ 2.9331303e-01, -3.3593619e+00,  4.6958623e+00,\n",
       "          -1.5954590e-01],\n",
       "         [-8.7305241e+00,  3.5491323e-01, -6.8071527e+00,\n",
       "           1.3208512e+00],\n",
       "         [ 4.6266570e+00, -1.9097958e+00,  3.9135993e+00,\n",
       "          -2.1454210e+00],\n",
       "         [ 8.2249060e+00,  7.7000933e+00, -4.6622005e+00,\n",
       "           6.7781959e+00]]],\n",
       "\n",
       "\n",
       "       [[[-1.5639396e+00, -4.8078637e+00,  2.1227171e+00,\n",
       "           2.9241433e+00],\n",
       "         [ 6.5212746e+00,  1.9745632e+00,  6.6896262e+00,\n",
       "           1.2103237e+00],\n",
       "         [-3.2054813e+00,  6.3777285e+00,  3.4855826e+00,\n",
       "           2.5296249e+00],\n",
       "         [-1.3363426e+01, -5.8076572e+00,  8.9884682e+00,\n",
       "          -1.1300645e-03],\n",
       "         [ 2.5752850e+00, -1.0001135e+00,  3.2755671e+00,\n",
       "           1.7415512e+00]],\n",
       "\n",
       "        [[ 3.2895024e+00,  2.0446506e+00, -5.2225003e+00,\n",
       "          -5.4568376e-02],\n",
       "         [ 6.6462164e+00,  9.5595378e-01, -1.5530775e+00,\n",
       "          -7.1931767e+00],\n",
       "         [-3.0641766e+00, -6.3071847e+00,  1.5715875e-02,\n",
       "           8.5708246e+00],\n",
       "         [-3.8544786e+00, -1.6681530e+00,  3.9805100e+00,\n",
       "          -6.9775867e+00],\n",
       "         [ 6.5435734e+00,  3.3826208e+00,  3.3534784e+00,\n",
       "           8.1669130e+00]],\n",
       "\n",
       "        [[ 4.3902678e+00,  5.7081139e-01, -4.1711679e+00,\n",
       "           4.6123357e+00],\n",
       "         [ 1.1366513e+01,  4.2953315e+00, -4.6806746e+00,\n",
       "          -9.8347616e+00],\n",
       "         [ 5.9221802e+00,  3.8958404e+00, -1.5428869e+01,\n",
       "           2.1020629e+00],\n",
       "         [-2.4811587e+00, -4.5312123e+00,  2.6825121e-01,\n",
       "          -1.1326074e+01],\n",
       "         [ 8.3607473e+00,  1.8990581e+00, -4.7622986e+00,\n",
       "           5.5646329e+00]],\n",
       "\n",
       "        [[ 9.5348418e-01, -5.3790879e+00, -4.4457975e-01,\n",
       "           9.7573072e-01],\n",
       "         [-2.2229867e+00,  6.0999107e-01,  5.5781879e+00,\n",
       "          -4.5518699e+00],\n",
       "         [ 5.9536681e+00, -2.3498695e+00,  5.9438567e+00,\n",
       "           8.5134964e+00],\n",
       "         [-3.7233040e+00, -3.9967704e+00,  9.3734493e+00,\n",
       "          -6.7462335e+00],\n",
       "         [ 6.4231672e+00,  6.1509132e+00,  2.5358253e+00,\n",
       "           4.9338036e+00]],\n",
       "\n",
       "        [[-5.5152950e+00, -9.4907236e-01,  2.3168836e+00,\n",
       "          -2.2457328e+00],\n",
       "         [-4.3015413e+00,  1.0796385e+00,  5.2618327e+00,\n",
       "           4.7808623e-01],\n",
       "         [-1.6509786e+00,  2.8685496e+00,  1.7744191e+00,\n",
       "          -8.1045699e-01],\n",
       "         [-3.5087345e+00, -1.4462321e+00,  1.0492891e+00,\n",
       "           1.7370483e+00],\n",
       "         [-4.8451605e+00,  3.0257106e+00,  6.0946321e-01,\n",
       "           2.3239434e+00]]]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=tf.random.normal([2,5,5,3]) # 模拟输入3通道，高度为5\n",
    "# 按照[k,k,cin,cout]格式创建W张量， 4个3x3大小的卷积核\n",
    "w=tf.random.normal([3,3,3,4])\n",
    "# 步长为1，padding为1\n",
    "out=tf.nn.conv2d(x,w,strides=1,padding=[[0,0],[1,1],[1,1],[0,0]])\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5, 5, 4), dtype=float32, numpy=\n",
       "array([[[[  1.5996565 ,  -0.37725994,   2.0744011 ,  -1.9507283 ],\n",
       "         [  0.02370794,   4.6912622 ,  -5.9282284 ,  -3.3402786 ],\n",
       "         [ -0.41557088,   0.83452094,  -1.8215061 ,  -1.7429786 ],\n",
       "         [ -3.486924  ,   1.4558746 ,   1.0992687 ,   0.60858893],\n",
       "         [  4.699833  ,  -1.1230516 ,  -2.1598723 ,   0.39094013]],\n",
       "\n",
       "        [[  1.0692463 ,  -5.3961363 ,   1.0165929 ,  -6.6751175 ],\n",
       "         [ -1.0737704 ,   3.4968464 ,   0.2250531 ,   4.2545166 ],\n",
       "         [  4.292991  ,   2.0232472 ,  -3.3121338 ,  -1.9753699 ],\n",
       "         [ -3.5752146 ,  -3.7635856 ,   8.089906  ,  -2.0340583 ],\n",
       "         [ -2.6952875 ,   0.6426771 ,   5.29564   ,   0.23095377]],\n",
       "\n",
       "        [[ -1.2633758 ,  -3.1731763 ,   2.8984022 ,   6.759421  ],\n",
       "         [  4.7566752 ,  -5.975336  ,   0.41779763,  -1.1319755 ],\n",
       "         [ -0.94991374,  -3.7249947 ,   6.3909373 ,  -9.661401  ],\n",
       "         [  2.0027816 ,   4.7913065 , -12.83888   ,   4.661256  ],\n",
       "         [  2.466167  ,  -0.1840114 ,  -7.6572213 ,  -1.7519417 ]],\n",
       "\n",
       "        [[ -2.5066137 ,  -0.26237723,  -3.1336517 ,  -4.7356772 ],\n",
       "         [  1.4266803 ,  -4.6164656 ,   5.1392417 ,  -4.622545  ],\n",
       "         [  0.12285979,  -3.479207  ,   8.285693  ,  -8.438127  ],\n",
       "         [  6.444398  ,   2.0502822 ,  -0.31969285,  -7.0249667 ],\n",
       "         [  4.517192  ,  -0.46422267,   3.3794627 ,  -4.8205004 ]],\n",
       "\n",
       "        [[ -4.532899  ,   0.99322945,   2.3210719 ,   6.905202  ],\n",
       "         [  0.3295588 ,  -1.8172839 ,  -0.85685426,  -1.1414446 ],\n",
       "         [ -2.9580936 ,   7.6755505 ,   2.6538942 ,  -0.97228116],\n",
       "         [ -1.4194465 ,   1.8512437 ,  -5.0810905 ,  -5.0132084 ],\n",
       "         [ -4.732985  ,   6.611788  ,  -1.2883803 ,   0.9786333 ]]],\n",
       "\n",
       "\n",
       "       [[[ -2.4597175 ,   0.3306567 ,   7.6713834 ,   1.4890931 ],\n",
       "         [ -2.5649462 ,   3.7848735 ,   3.145206  ,  -5.3382077 ],\n",
       "         [ -1.1039652 ,   2.9890683 ,  -0.2955353 ,  -0.842724  ],\n",
       "         [  3.561326  ,  -1.1365722 ,   4.2853885 ,  -3.2078185 ],\n",
       "         [  1.5960203 ,  -2.4280808 ,   2.5683167 ,  -0.49292845]],\n",
       "\n",
       "        [[  3.774602  ,   0.778239  ,   1.3004211 ,   3.8040848 ],\n",
       "         [  0.9509152 ,   5.0039954 ,  -8.114615  ,  -2.5055888 ],\n",
       "         [ -0.7875393 ,   4.408585  ,  -3.2659864 ,   4.5175295 ],\n",
       "         [ -4.4861436 ,   4.9584594 ,  -0.2425062 ,  -6.072285  ],\n",
       "         [ -0.43656367,   4.584831  ,  -1.3659825 ,  -1.046988  ]],\n",
       "\n",
       "        [[  4.538302  ,  -1.0399725 ,  -3.5553317 , -10.042115  ],\n",
       "         [  1.4890391 ,   1.9553381 ,  -0.48638448,   0.15573224],\n",
       "         [  6.329046  ,   0.17933856,  -1.5165961 ,  -4.988984  ],\n",
       "         [  0.04145113,   7.1049175 ,   0.8034781 ,  12.909832  ],\n",
       "         [  1.8084931 ,  -1.7981555 ,  -7.1056824 ,  -3.7582402 ]],\n",
       "\n",
       "        [[  1.6997563 ,   2.2169328 , -10.246197  ,  -4.53713   ],\n",
       "         [  2.5396411 ,  -4.499677  ,   7.837038  ,  -4.0502353 ],\n",
       "         [ -4.9327435 ,   5.341759  ,   8.910321  ,  -2.2036703 ],\n",
       "         [ 10.408298  ,   5.4501495 ,  -8.95429   , -13.9318285 ],\n",
       "         [  0.37210432,   1.1889284 ,  -0.13387156,   2.4664335 ]],\n",
       "\n",
       "        [[ -6.0263553 ,  -4.776422  ,  -1.7640094 ,  -0.20166302],\n",
       "         [  0.58603036,   5.1152134 ,  -0.7541394 ,   6.360615  ],\n",
       "         [  3.9601684 ,   8.823242  ,  -5.1490407 ,  -1.1599    ],\n",
       "         [  0.67487   ,   1.8734896 ,   1.1060579 ,  -6.880111  ],\n",
       "         [ -2.968271  ,   1.0817297 ,   1.7044761 ,   1.6969627 ]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 当padding='SAME'时可以得到输入、输出通大小的卷积层\n",
    "# 当strides步长＞1时，设置padding='SAME'得到高、宽成1/s倍的减少\n",
    "\n",
    "x=tf.random.normal([2,5,5,3])\n",
    "w=tf.random.normal([3,3,3,4])\n",
    "out1=tf.nn.conv2d(x,w,strides=1,padding='SAME')\n",
    "out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 2, 4), dtype=float32, numpy=\n",
       "array([[[[ 6.6389618e+00,  4.9656134e+00,  9.5027101e-01,\n",
       "          -1.0452413e+01],\n",
       "         [-8.5352612e-01,  3.7207146e+00, -4.7919331e+00,\n",
       "          -1.7244339e+00]],\n",
       "\n",
       "        [[-2.0570567e+00,  3.8826661e+00, -8.8624001e-02,\n",
       "          -2.7297938e+00],\n",
       "         [-4.8120511e-01, -6.7778497e+00,  3.0876822e+00,\n",
       "          -8.1023693e-02]]],\n",
       "\n",
       "\n",
       "       [[[-4.7666814e-02, -2.1229614e+01, -1.1502867e+00,\n",
       "          -4.1311979e+00],\n",
       "         [ 7.4135866e+00, -5.8804035e-01,  3.3095610e+00,\n",
       "           4.7074361e+00]],\n",
       "\n",
       "        [[ 1.8475413e-02,  6.9383812e+00,  8.5667772e+00,\n",
       "           3.6734943e+00],\n",
       "         [ 7.8917036e+00,  3.5888219e-01,  4.0520535e+00,\n",
       "          -3.4515421e+00]]]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=tf.random.normal([2,5,5,3])\n",
    "w=tf.random.normal([3,3,3,4])\n",
    "out2=tf.nn.conv2d(x,w,strides=3,padding='SAME')\n",
    "out2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷积层类\n",
    "**通过利用layers.Conv2D可以不需要手动定义卷积核W和偏执b张量**\n",
    "\n",
    "| 参数 | 含义 |\n",
    "|-----|-----|\n",
    "|filters|卷积核数量参数|\n",
    "|kernel_size|卷积核大小|\n",
    "|strides|步长|\n",
    "|padding|填充|\n",
    "\n",
    "**创建一个4个3x3大小的卷积核，步长为1，padding方案为SAME**\n",
    "\n",
    "```\n",
    "# 利用layers.Conv2D新建卷积层\n",
    "layer=layers.Conv2D(4, kernel_size=3, strides=1,padding='SAME')\n",
    "```\n",
    "\n",
    "**如果卷积核高宽不等，则需要将其改为元组类型，如下创建4个3x3大小的卷积核,竖直方向移动步长为2，水平方向移动步长为1**\n",
    "```\n",
    "layer=layers.Conv2D(4, kernel_size=(3,4),strides=(2,1),padding='SAME')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 5, 5, 4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "# 创建卷积层类\n",
    "x=tf.random.normal([2,5,5,3])\n",
    "layer=layers.Conv2D(4, kernel_size=3, strides=1, padding='SAME')\n",
    "out=layer(x) # 向前计算\n",
    "out.shape # 输出张量的shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'conv2d/kernel:0' shape=(3, 3, 3, 4) dtype=float32, numpy=\n",
       " array([[[[ 0.0119963 , -0.2558023 , -0.19505283,  0.0826059 ],\n",
       "          [ 0.22299966, -0.22749892,  0.15276456,  0.07288918],\n",
       "          [ 0.0684832 , -0.09449752,  0.2959788 ,  0.11613044]],\n",
       " \n",
       "         [[ 0.19506517,  0.29050717,  0.21436343, -0.21654359],\n",
       "          [ 0.25795648, -0.14683722, -0.12272321, -0.06969047],\n",
       "          [ 0.22993293,  0.19700286,  0.08925298,  0.18055224]],\n",
       " \n",
       "         [[-0.17555985,  0.30768165, -0.05694309,  0.00183833],\n",
       "          [-0.16997766, -0.16853988, -0.17461179,  0.2567534 ],\n",
       "          [ 0.05512866,  0.17868292, -0.2386652 ,  0.09391412]]],\n",
       " \n",
       " \n",
       "        [[[ 0.15268692,  0.02194017, -0.1472945 ,  0.22155687],\n",
       "          [-0.19386816,  0.1289495 , -0.10931523, -0.1786117 ],\n",
       "          [ 0.10669419,  0.02889907,  0.19042185, -0.2114523 ]],\n",
       " \n",
       "         [[-0.2362556 , -0.01949885, -0.30372262, -0.22771832],\n",
       "          [-0.02318135, -0.2330805 , -0.23777997, -0.27943504],\n",
       "          [-0.15052779, -0.23210907,  0.08729213,  0.30711862]],\n",
       " \n",
       "         [[ 0.13351828, -0.12514994,  0.260156  , -0.2522744 ],\n",
       "          [-0.18743077, -0.2016047 ,  0.00167456,  0.1456157 ],\n",
       "          [ 0.09033045,  0.15475962, -0.0797873 , -0.25253132]]],\n",
       " \n",
       " \n",
       "        [[[ 0.00138634, -0.08765429, -0.16742577, -0.06276955],\n",
       "          [ 0.29463676, -0.15508188,  0.22640881,  0.12159702],\n",
       "          [-0.22855651,  0.14413765, -0.26413083,  0.24093875]],\n",
       " \n",
       "         [[-0.03359589, -0.21446413,  0.12347612,  0.06402317],\n",
       "          [-0.13563333, -0.2698715 ,  0.30360475,  0.28918406],\n",
       "          [ 0.24295107,  0.1453731 ,  0.05453062,  0.02546528]],\n",
       " \n",
       "         [[-0.04846922,  0.20245883, -0.21767682, -0.0861973 ],\n",
       "          [-0.07669212, -0.21248564,  0.00114501,  0.00902238],\n",
       "          [ 0.13511917, -0.2388292 , -0.14062117,  0.24060485]]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'conv2d/bias:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 返回所有待优化张量列表\n",
    "layer.trainable_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet-5实战\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets: (60000, 28, 28) (60000,) 0 255\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_39 (Conv2D)           multiple                  60        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling multiple                  0         \n",
      "_________________________________________________________________\n",
      "re_lu_38 (ReLU)              multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           multiple                  880       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling multiple                  0         \n",
      "_________________________________________________________________\n",
      "re_lu_39 (ReLU)              multiple                  0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             multiple                  48120     \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             multiple                  10164     \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             multiple                  850       \n",
      "=================================================================\n",
      "Total params: 60,074\n",
      "Trainable params: 60,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0 loss: 2.305769\n",
      "test acc: 0.2411\n",
      "100 loss: 0.37558165\n",
      "200 loss: 0.12305001\n",
      "300 loss: 0.08789174\n",
      "400 loss: 0.09936469\n",
      "500 loss: 0.07087776\n",
      "test acc: 0.9829\n",
      "600 loss: 0.06551684\n",
      "700 loss: 0.07022412\n",
      "800 loss: 0.069670804\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_FallbackException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda2/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mconcat_v2\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ConcatV2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1172\u001b[0;31m         tld.op_callbacks, values, axis)\n\u001b[0m\u001b[1;32m   1173\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_FallbackException\u001b[0m: This function does not handle the case of the path where all inputs are not already EagerTensors.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-0ed259e0a703>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0my_onehot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m# 计算交叉熵损失函数，标量\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriteon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_onehot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mloss_meter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/losses.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m    141\u001b[0m         y_true, y_pred, sample_weight)\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m       \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m       return losses_utils.compute_weighted_loss(\n\u001b[1;32m    145\u001b[0m           losses, sample_weight, reduction=self._get_reduction())\n",
      "\u001b[0;32m~/anaconda2/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/losses.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m    244\u001b[0m       y_pred, y_true = tf_losses_util.squeeze_or_expand_dimensions(\n\u001b[1;32m    245\u001b[0m           y_pred, y_true)\n\u001b[0;32m--> 246\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/losses.py\u001b[0m in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(y_true, y_pred, from_logits, label_smoothing)\u001b[0m\n\u001b[1;32m   1525\u001b[0m   y_true = smart_cond.smart_cond(label_smoothing,\n\u001b[1;32m   1526\u001b[0m                                  _smooth_labels, lambda: y_true)\n\u001b[0;32m-> 1527\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical_crossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrom_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m   4562\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mfrom_logits\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4563\u001b[0m     return nn.softmax_cross_entropy_with_logits_v2(\n\u001b[0;32m-> 4564\u001b[0;31m         labels=target, logits=output, axis=axis)\n\u001b[0m\u001b[1;32m   4565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4566\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36msoftmax_cross_entropy_with_logits_v2\u001b[0;34m(labels, logits, axis, name)\u001b[0m\n\u001b[1;32m   3217\u001b[0m   \"\"\"\n\u001b[1;32m   3218\u001b[0m   return softmax_cross_entropy_with_logits_v2_helper(\n\u001b[0;32m-> 3219\u001b[0;31m       labels=labels, logits=logits, axis=axis, name=name)\n\u001b[0m\u001b[1;32m   3220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m~/anaconda2/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36msoftmax_cross_entropy_with_logits_v2_helper\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3312\u001b[0m     \u001b[0;31m# Make precise_logits and labels into matrices.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3313\u001b[0;31m     \u001b[0mprecise_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_flatten_outer_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecise_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3314\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_flatten_outer_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m_flatten_outer_dims\u001b[0;34m(logits)\u001b[0m\n\u001b[1;32m   2922\u001b[0m   last_dim_size = array_ops.slice(\n\u001b[1;32m   2923\u001b[0m       array_ops.shape(logits), [math_ops.subtract(rank, 1)], [1])\n\u001b[0;32m-> 2924\u001b[0;31m   \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_dim_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2926\u001b[0m   \u001b[0;31m# Set output shape if known.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1604\u001b[0m           dtype=dtypes.int32).get_shape().assert_has_rank(0)\n\u001b[1;32m   1605\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1606\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mconcat_v2\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m         return concat_v2_eager_fallback(\n\u001b[0;32m-> 1177\u001b[0;31m             values, axis, name=name, ctx=_ctx)\n\u001b[0m\u001b[1;32m   1178\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mconcat_v2_eager_fallback\u001b[0;34m(values, axis, name, ctx)\u001b[0m\n\u001b[1;32m   1207\u001b[0m         \"'concat_v2' Op, not %r.\" % values)\n\u001b[1;32m   1208\u001b[0m   \u001b[0m_attr_N\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1209\u001b[0;31m   \u001b[0m_attr_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs_to_matching_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1210\u001b[0m   \u001b[0m_attr_Tidx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs_to_matching_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36margs_to_matching_eager\u001b[0;34m(l, ctx, default_dtype)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m   \u001b[0;31m# TODO(slebedev): consider removing this as it leaks a Keras concept.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m   \u001b[0;31m# TODO(slebedev): consider removing this as it leaks a Keras concept.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpreferred_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0mpreferred_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconversion_func\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensor_conversion_registry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;31m# If dtype is None but preferred_dtype is not None, we try to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m     \u001b[0;31m# cast to preferred_dtype first.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, optimizers, Sequential, metrics, losses\n",
    "\n",
    "log_dir = './tensorboard_img/'\n",
    "summary_writer=tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "def preprocess(x, y):\n",
    "    x=tf.cast(x, dtype=tf.float32)/ 255\n",
    "    y=tf.cast(y, dtype=tf.int32)\n",
    "    return x,y\n",
    "\n",
    "batchsz=128\n",
    "(x, y), (x_val, y_val) = datasets.mnist.load_data()\n",
    "print('datasets:', x.shape, y.shape, x.min(), x.max())\n",
    "\n",
    "db = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "db = db.map(preprocess).shuffle(60000).batch(batchsz).repeat(10)\n",
    "\n",
    "ds_val = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "ds_val = ds_val.map(preprocess).batch(batchsz)\n",
    "\n",
    "network = Sequential([\n",
    "    layers.Conv2D(6, kernel_size=3, strides=1), # 第一层卷积 6个3x3\n",
    "    layers.MaxPooling2D(pool_size=2, strides=2), # 宽高减半的池化层\n",
    "    layers.ReLU(), #激活函数\n",
    "    layers.Conv2D(16, kernel_size=3, strides=1), # 第二层卷积 16个3x3\n",
    "    layers.MaxPooling2D(pool_size=2, strides=2), # 宽高减半的池化层\n",
    "    layers.ReLU(), #激活函数\n",
    "    layers.Flatten(), # 打平层，方便全连接处理\n",
    "    \n",
    "    layers.Dense(120, activation='relu'), # 120个结点的全连接层\n",
    "    layers.Dense(84, activation='relu'), # 全连接层 84节点\n",
    "    layers.Dense(10), # 全连接层 10结点\n",
    "])\n",
    "\n",
    "network.build(input_shape=(4, 28, 28, 1))\n",
    "# 统计网络信息\n",
    "network.summary()\n",
    "\n",
    "# 创建损失函数的类，在实际计算中调用类的实例即可\n",
    "criteon=losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "optimizer = optimizers.Adam(lr=0.01)\n",
    "\n",
    "acc_meter = metrics.Accuracy()\n",
    "loss_meter = metrics.Mean()\n",
    "\n",
    "for step, (x,y) in enumerate(db):\n",
    "    \n",
    "    # 构建梯度记录环境\n",
    "    with tf.GradientTape() as tape:\n",
    "        # 插入通道维度, =>[b,28,28,1]\n",
    "        x=tf.expand_dims(x, axis=3) # 增加维度\n",
    "        # 向前计算,获得10类别的概率分布 [b, 784] = > [b,10]\n",
    "        out = network(x)\n",
    "        # 真实标签One-hot编码 [b]=>[b,10]\n",
    "        y_onehot = tf.one_hot(y, depth=10)\n",
    "        # 计算交叉熵损失函数，标量\n",
    "        loss = criteon(y_onehot, out)\n",
    "        loss_meter.update_state(loss)\n",
    "        \n",
    "        with summary_writer.as_default(): # 写入环境\n",
    "            tf.summary.scalar('train-loss', float(loss), step=step)\n",
    "      \n",
    "    # 自动计算梯度\n",
    "    grads = tape.gradient(loss, network.trainable_variables)\n",
    "    # 自动更新参数\n",
    "    optimizer.apply_gradients(zip(grads, network.trainable_variables))\n",
    "    \n",
    "    if step%100==0:\n",
    "        \n",
    "        print(step, 'loss:', loss_meter.result().numpy())\n",
    "        loss_meter.reset_states()\n",
    "        \n",
    "     # evaluate\n",
    "    if step % 500 == 0:\n",
    "        # 记录预测正确的数量， 总样本数量\n",
    "        correct, total=0,0\n",
    "        for step, (x,y) in enumerate(ds_val):\n",
    "            # 插入通道维数, => [b, 28, 28, 1]\n",
    "            x=tf.expand_dims(x, axis=3)\n",
    "            # 向前计算, 获得10类别的预测分布, [b, 784]=>[b,10]\n",
    "            out = network(x)\n",
    "            # 真实流程是先经过softmax再argmax\n",
    "            # 但是由于softmax不改变元素大小的相对关系，故省去\n",
    "            pred=tf.argmax(out, axis=-1)\n",
    "            y=tf.cast(y, tf.int64)\n",
    "            # 统计预测正确数量\n",
    "            correct += float(tf.reduce_sum(tf.cast(tf.equal(pred, y), tf.float32)))\n",
    "            # 统计预测样本总数\n",
    "            total += x.shape[0]\n",
    "            \n",
    "            \n",
    "        # 计算准确率\n",
    "        print('test acc:',correct/total)\n",
    "        \n",
    "        val_images=x[:10]\n",
    "        with summary_writer.as_default():\n",
    "                tf.summary.scalar('test-acc', float(correct/total), step=step)\n",
    "                tf.summary.image(\"val-onebyone-images:\", val_images, max_outputs=9, step=step)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR10 实战"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000,) (10000, 32, 32, 3) (10000,)\n",
      "sample: (128, 32, 32, 3) (128,) tf.Tensor(-1.0, shape=(), dtype=float32) tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           multiple                  1792      \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           multiple                  36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           multiple                  73856     \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           multiple                  147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           multiple                  295168    \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           multiple                  590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           multiple                  1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           multiple                  2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           multiple                  2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           multiple                  2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 multiple                  0         \n",
      "=================================================================\n",
      "Total params: 9,404,992\n",
      "Trainable params: 9,404,992\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  131328    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  32896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  1290      \n",
      "=================================================================\n",
      "Total params: 165,514\n",
      "Trainable params: 165,514\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0 0 loss: 2.302992820739746\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f9ac9a04650f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;31m# if __name__ == '__main__':\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;31m#     main()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-f9ac9a04650f>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf/lib/python3.6/site-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m~/anaconda2/envs/tf/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"gradient_tape/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_Conv2DGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    590\u001b[0m           \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m           \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m           data_format=data_format),\n\u001b[0m\u001b[1;32m    593\u001b[0m       gen_nn_ops.conv2d_backprop_filter(\n\u001b[1;32m    594\u001b[0m           \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d_backprop_input\u001b[0;34m(input_sizes, filter, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1239\u001b[0m         \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"padding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m         \u001b[0;34m\"explicit_paddings\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data_format\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1241\u001b[0;31m         \"dilations\", dilations)\n\u001b[0m\u001b[1;32m   1242\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import  tensorflow as tf\n",
    "from    tensorflow.keras import layers, optimizers, datasets, Sequential\n",
    "import  os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "tf.random.set_seed(2345)\n",
    "\n",
    "conv_layers = [ # 5 units of conv + max pooling\n",
    "    # unit 1\n",
    "    layers.Conv2D(64, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.Conv2D(64, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same'),\n",
    "\n",
    "    # unit 2\n",
    "    layers.Conv2D(128, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.Conv2D(128, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same'),\n",
    "\n",
    "    # unit 3\n",
    "    layers.Conv2D(256, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.Conv2D(256, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same'),\n",
    "\n",
    "    # unit 4\n",
    "    layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same'),\n",
    "\n",
    "    # unit 5\n",
    "    layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same')\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "def preprocess(x, y):\n",
    "    # [0~1]\n",
    "    x = 2*tf.cast(x, dtype=tf.float32) / 255.-1\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "    return x,y\n",
    "\n",
    "\n",
    "(x,y), (x_test, y_test) = datasets.cifar10.load_data()\n",
    "y = tf.squeeze(y, axis=1)\n",
    "y_test = tf.squeeze(y_test, axis=1)\n",
    "print(x.shape, y.shape, x_test.shape, y_test.shape)\n",
    "\n",
    "\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "train_db = train_db.shuffle(1000).map(preprocess).batch(128)\n",
    "\n",
    "test_db = tf.data.Dataset.from_tensor_slices((x_test,y_test))\n",
    "test_db = test_db.map(preprocess).batch(64)\n",
    "\n",
    "sample = next(iter(train_db))\n",
    "print('sample:', sample[0].shape, sample[1].shape,\n",
    "      tf.reduce_min(sample[0]), tf.reduce_max(sample[0]))\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    # [b, 32, 32, 3] => [b, 1, 1, 512]\n",
    "    conv_net = Sequential(conv_layers)\n",
    "\n",
    "    fc_net = Sequential([\n",
    "        layers.Dense(256, activation=tf.nn.relu),\n",
    "        layers.Dense(128, activation=tf.nn.relu),\n",
    "        layers.Dense(10, activation=None),\n",
    "    ])\n",
    "\n",
    "    conv_net.build(input_shape=[None, 32, 32, 3])\n",
    "    fc_net.build(input_shape=[None, 512])\n",
    "    conv_net.summary()\n",
    "    fc_net.summary()\n",
    "    optimizer = optimizers.Adam(lr=1e-4)\n",
    "\n",
    "    # [1, 2] + [3, 4] => [1, 2, 3, 4]\n",
    "    variables = conv_net.trainable_variables + fc_net.trainable_variables\n",
    "\n",
    "    for epoch in range(50):\n",
    "\n",
    "        for step, (x,y) in enumerate(train_db):\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                # [b, 32, 32, 3] => [b, 1, 1, 512]\n",
    "                out = conv_net(x)\n",
    "                # flatten, => [b, 512]\n",
    "                out = tf.reshape(out, [-1, 512])\n",
    "                # [b, 512] => [b, 10]\n",
    "                logits = fc_net(out)\n",
    "                # [b] => [b, 10]\n",
    "                y_onehot = tf.one_hot(y, depth=10)\n",
    "                # compute loss\n",
    "                loss = tf.losses.categorical_crossentropy(y_onehot, logits, from_logits=True)\n",
    "                loss = tf.reduce_mean(loss)\n",
    "\n",
    "            grads = tape.gradient(loss, variables)\n",
    "            optimizer.apply_gradients(zip(grads, variables))\n",
    "\n",
    "            if step %100 == 0:\n",
    "                print(epoch, step, 'loss:', float(loss))\n",
    "\n",
    "\n",
    "\n",
    "        total_num = 0\n",
    "        total_correct = 0\n",
    "        for x,y in test_db:\n",
    "\n",
    "            out = conv_net(x)\n",
    "            out = tf.reshape(out, [-1, 512])\n",
    "            logits = fc_net(out)\n",
    "            prob = tf.nn.softmax(logits, axis=1)\n",
    "            pred = tf.argmax(prob, axis=1)\n",
    "            pred = tf.cast(pred, dtype=tf.int32)\n",
    "\n",
    "            correct = tf.cast(tf.equal(pred, y), dtype=tf.int32)\n",
    "            correct = tf.reduce_sum(correct)\n",
    "\n",
    "            total_num += x.shape[0]\n",
    "            total_correct += int(correct)\n",
    "\n",
    "        acc = total_correct / total_num\n",
    "        print(epoch, 'acc:', acc)\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main()\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 转置卷积的实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# 创建4x4大小的输入\n",
    "x=tf.range(16)+1\n",
    "x=tf.reshape(x, [1,4,4,1])\n",
    "x=tf.cast(x, tf.float32)\n",
    "# 创建3x3的卷积核\n",
    "w=tf.constant([[-1,2,-3.],[4,-5,6],[-7,8,-9]])\n",
    "w=tf.expand_dims(w, axis=2)\n",
    "w=tf.expand_dims(w, axis=3)\n",
    "# 普通卷积运算\n",
    "out=tf.nn.conv2d(x,w,strides=1,padding='VALID')\n",
    "out\n",
    "# 恢复4x4的大小\n",
    "xx=tf.nn.conv2d_transpose(out,w,strides=1,padding='VALID',output_shape=[1,4,4,1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR10与ResNet18实战"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
