{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.6590012 , 0.24243298, 0.09856589], dtype=float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 常见网络类层\n",
    "# 在tf.keras.layers命名空间中提供了许多大量的常见网络层的类,\n",
    "# 例如 全连接层、激活函数层、池化层、卷积层、循环神经网络层等\n",
    "# 对于这些网络层类只需要创建时指定相关参数，并且调用__call__方法即可完成向前计算\n",
    "# 在__call__方法中，Keras会自动调用每个层的向前传播逻辑，这些逻辑一般实现在类的call函数中\n",
    "\n",
    "# 搭建Softmax层 利用tf.nn.softmax和利用layers.Soiftmax(axis)类搭建，axis为指定Softmax的维度\n",
    "\n",
    "import tensorflow as tf\n",
    "# 导入keras模型\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers # 导入常见网络层类\n",
    "# 创建Softmax层\n",
    "x = tf.constant([2.,1.,0.1]) # 创建输入张量\n",
    "layer = layers.Softmax(axis=-1) # 创建Softmax层\n",
    "out = layer(x)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.6590012 , 0.24243298, 0.09856589], dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 利用tf.nn.softmax()函数完成计算\n",
    "out = tf.nn.softmax(x) # 调用softmax函数完成向前计算\n",
    "out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
       "array([[0.      , 0.      ],\n",
       "       [0.      , 0.      ],\n",
       "       [0.      , 0.      ],\n",
       "       [0.      , 0.728432]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 网络容器\n",
    "# 当网络层数变得非常多的时候可以利用网络容器Sequential将多个网络层封装成一个\n",
    "# 大网络模型，只需要调用网络模型的实例一次即可完成数据从第一层到最末层的顺序传播运算。\n",
    "# 导入Sequential容器\n",
    "from tensorflow.keras import layers, Sequential\n",
    "network = Sequential([ # 封装成一个网络\n",
    "    layers.Dense(3, activation=None), # 全连接层，此处不使用激活函数\n",
    "    layers.ReLU(), # 激活函数层\n",
    "    layers.Dense(2, activation=None), # 全连接层，此处不适用激活函数\n",
    "    layers.ReLU(), # 激活函数层\n",
    "])\n",
    "x = tf.random.normal([4, 3])\n",
    "out = network(x) # 输入从第一层开始， 逐层传播至输出层，并返回输出层的输出\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  15        \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  12        \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               multiple                  0         \n",
      "=================================================================\n",
      "Total params: 27\n",
      "Trainable params: 27\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 利用add方法添加新的网络层，实现动态创建网络的功能\n",
    "from tensorflow.keras import layers, Sequential\n",
    "layers_num = 2 # 堆叠两次\n",
    "network = Sequential([]) # 先创建空的网络容器\n",
    "for _ in range(layers_num):\n",
    "    network.add(layers.Dense(3)) # 添加全连接层\n",
    "    network.add(layers.ReLU()) # 添加激活函数\n",
    "network.build(input_shape=(4, 4)) # 创建网络参数\n",
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense/kernel:0 (4, 3)\n",
      "dense/bias:0 (3,)\n",
      "dense_1/kernel:0 (3, 3)\n",
      "dense_1/bias:0 (3,)\n"
     ]
    }
   ],
   "source": [
    "# 打印网络优化的待优化参数名与shape\n",
    "for p in network.trainable_variables:\n",
    "    print(p.name, p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              multiple                  200960    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  32896     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  8256      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              multiple                  2080      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              multiple                  330       \n",
      "=================================================================\n",
      "Total params: 244,522\n",
      "Trainable params: 244,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 模型装配、模型训练\n",
    "# 模型装配\n",
    "# 创建5层的全连接网络用于MNIST手写数字识别网络\n",
    "from tensorflow.keras import Sequential, layers\n",
    "import tensorflow as tf\n",
    "network = Sequential([\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(10)\n",
    "])\n",
    "network.build(input_shape=(4, 28*28))\n",
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_db' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-09add7c026d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# 指定训练集为train_db，验证集为val_db，训练5个epochs，每2个epochs验证一次\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# 返回训练轨迹信息保存在history对象中\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_db\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_db\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_db' is not defined"
     ]
    }
   ],
   "source": [
    "# 导入优化器，损失函数模块\n",
    "from tensorflow.keras import optimizers, losses\n",
    "# 模型装配\n",
    "# 采用Adam优化器，学习率为0.01；采用交叉熵损失函数，包含Softmax\n",
    "network.compile(optimizer=optimizers.Adam(lr=0.01),\n",
    "                loss=losses.CategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'] # 设置测量指标为准确率\n",
    ")\n",
    "\n",
    "# 模型训练\n",
    "# 指定训练集为train_db，验证集为val_db，训练5个epochs，每2个epochs验证一次\n",
    "# 返回训练轨迹信息保存在history对象中\n",
    "history = network.fit(train_db, epochs=5, validation_data=val_db, validation_freq=2)\n",
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets: (60000, 28, 28) (60000,) 0 255\n",
      "(128, 784) (128, 10)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  200960    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  32896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  2080      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  330       \n",
      "=================================================================\n",
      "Total params: 244,522\n",
      "Trainable params: 244,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2858 - accuracy: 0.9132\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 0.1376 - accuracy: 0.9605 - val_loss: 0.1305 - val_accuracy: 0.9650\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1070 - accuracy: 0.9705\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.1031 - accuracy: 0.9727 - val_loss: 0.1343 - val_accuracy: 0.9646\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0925 - accuracy: 0.9754\n",
      "79/79 [==============================] - 1s 18ms/step - loss: 0.1241 - accuracy: 0.9720\n",
      "tf.Tensor(\n",
      "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7\n",
      " 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 2 9 3 7 4 6 4 3 0 7 0 2 9\n",
      " 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6 9 6 0 5 4 9 9 2 1 9 4 8\n",
      " 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5], shape=(128,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7\n",
      " 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9\n",
      " 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6 9 6 0 5 4 9 9 2 1 9 4 8\n",
      " 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5], shape=(128,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# 手写数字识别MNIST \n",
    "# 样本量batchsz：128\n",
    "# 训练批次epoch = 5\n",
    "# (x, y) 图像和编号\n",
    "# (x_val, y_val) 测试图像和其编号\n",
    "import tensorflow as tf\n",
    "# 导入数据集datasets，层layers，网络容器Sequential, 优化器optimizers, 损失函数losses\n",
    "# 测量指标metrics\n",
    "from tensorflow.keras import datasets, layers, optimizers, losses, metrics\n",
    "\n",
    "\n",
    "# 预处理函数\n",
    "# 图像打平， 序号利用onehot编码\n",
    "# x:图像 y:图像序号\n",
    "def preprocess(x, y):\n",
    "    x = tf.cast(x, dtype=tf.float32) / 255\n",
    "    x = tf.reshape(x, [28*28]) # 打平\n",
    "    y = tf.cast(y, dtype=tf.int32) \n",
    "    y = tf.one_hot(y, depth=10) # onehot编码 深度为10\n",
    "    return x,y\n",
    "\n",
    "# 训练样本集大小为128\n",
    "batchsz = 128\n",
    "(x, y),(x_val, y_val) = datasets.mnist.load_data()\n",
    "print('datasets:', x.shape, y.shape, x.min(), x.max())\n",
    "\n",
    "# 数据集\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x, y)) # 切片\n",
    "train_db = train_db.map(preprocess).shuffle(60000).batch(batchsz) # 随即打散获得128个训练样本\n",
    "val_db = tf.data.Dataset.from_tensor_slices((x_val, y_val)) # 切片获得测试数据\n",
    "val_db = val_db.map(preprocess).batch(batchsz)\n",
    "\n",
    "# 迭代样本集\n",
    "sample = next(iter(train_db))\n",
    "print(sample[0].shape, sample[1].shape)\n",
    "\n",
    "# 定义5层的全连接网络\n",
    "network = Sequential([\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(10)\n",
    "])\n",
    "network.build(input_shape=(4, 28*28))\n",
    "network.summary()\n",
    "\n",
    "# 模型装配\n",
    "# 采用Adam优化器，学习率为0.01；采用交叉熵损失函数，包含Softmax\n",
    "network.compile(optimizer=optimizers.Adam(lr=0.01),\n",
    "                loss=losses.CategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'] # 设置测量指标为准确率\n",
    ")\n",
    "\n",
    "# 模型训练 样本集为train_db epochs为5 验证数据为val_db 每2个epoch验证一次\n",
    "network.fit(train_db, epochs=5, validation_data=val_db, validation_freq=2)\n",
    "network.evaluate(val_db) # 返回损失值和模型度量值\n",
    "\n",
    "# 迭代测试数据\n",
    "sample = next(iter(val_db))\n",
    "x = sample[0]\n",
    "y = sample[1] # one_hot\n",
    "pred = network.predict(x) # [b,10]\n",
    "y = tf.argmax(y, axis=1)\n",
    "pred = tf.argmax(pred, axis=1)\n",
    "\n",
    "print(pred)\n",
    "print(y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-8b15863c49bf>:9: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([<tf.Variable 'w:0' shape=(4, 3) dtype=float32, numpy=\n",
       "  array([[ 0.44240594, -0.07384259,  0.36983418],\n",
       "         [ 0.02167153,  0.51211226,  0.37494767],\n",
       "         [-0.78961504,  0.02941352, -0.74860394],\n",
       "         [-0.04101104, -0.52576876, -0.49299306]], dtype=float32)>],\n",
       " [<tf.Variable 'w:0' shape=(4, 3) dtype=float32, numpy=\n",
       "  array([[ 0.44240594, -0.07384259,  0.36983418],\n",
       "         [ 0.02167153,  0.51211226,  0.37494767],\n",
       "         [-0.78961504,  0.02941352, -0.74860394],\n",
       "         [-0.04101104, -0.52576876, -0.49299306]], dtype=float32)>])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 自定义网络层\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, optimizers, losses, metrics\n",
    "class MyDense(layers.Layer):\n",
    "    # 自定义网络层\n",
    "    def __init__(self, inp_dim, outp_dim):\n",
    "        super(MyDense, self).__init__()\n",
    "        # 创建权值张量并添加到类管理列表中，设置为需要优化\n",
    "        self.kernel = self.add_variable('w', [inp_dim, outp_dim], trainable=True)\n",
    "        \n",
    "net = MyDense(4, 3) #创建输入节点为4， 输出节点为3的自定义层\n",
    "net.variables, net.trainable_variables # C哈看自定义层的参数列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "my_dense_20 (MyDense)        multiple                  200704    \n",
      "_________________________________________________________________\n",
      "my_dense_21 (MyDense)        multiple                  32768     \n",
      "_________________________________________________________________\n",
      "my_dense_22 (MyDense)        multiple                  8192      \n",
      "_________________________________________________________________\n",
      "my_dense_23 (MyDense)        multiple                  2048      \n",
      "_________________________________________________________________\n",
      "my_dense_24 (MyDense)        multiple                  320       \n",
      "=================================================================\n",
      "Total params: 244,032\n",
      "Trainable params: 244,032\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"my_model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "my_dense_25 (MyDense)        multiple                  200704    \n",
      "_________________________________________________________________\n",
      "my_dense_26 (MyDense)        multiple                  32768     \n",
      "_________________________________________________________________\n",
      "my_dense_27 (MyDense)        multiple                  8192      \n",
      "_________________________________________________________________\n",
      "my_dense_28 (MyDense)        multiple                  2048      \n",
      "_________________________________________________________________\n",
      "my_dense_29 (MyDense)        multiple                  320       \n",
      "=================================================================\n",
      "Total params: 244,032\n",
      "Trainable params: 244,032\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 自定义网络层\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, optimizers, losses, metrics, Sequential\n",
    "class MyDense(layers.Layer):\n",
    "    # 自定义网络层\n",
    "    def __init__(self, inp_dim, outp_dim):\n",
    "        super(MyDense, self).__init__()\n",
    "        # 创建权值张量并添加到类管理列表中，设置为需要优化\n",
    "        self.kernel = self.add_variable('w', [inp_dim, outp_dim], trainable=True)\n",
    "    \n",
    "    def call(self, inputs, training=None):\n",
    "        # 定义向前计算逻辑\n",
    "        # X @ W\n",
    "        out = inputs @ self.kernel\n",
    "        # 执行向前计算的激活函数\n",
    "        out = tf.nn.relu(out)\n",
    "        return out\n",
    "    \n",
    "# net = MyDense(4, 3) #创建输入节点为4， 输出节点为3的自定义层\n",
    "# net.variables, net.trainable_variables # 查看自定义层的参数列表\n",
    "\n",
    "# 使用自定义的网络层来实现MNIST手写数字识别\n",
    "network = Sequential([MyDense(784, 256),\n",
    "                      MyDense(256, 128),\n",
    "                      MyDense(128, 64),\n",
    "                      MyDense(64, 32),\n",
    "                      MyDense(32, 10)\n",
    "])\n",
    "network.build(input_shape=(None, 28*28))\n",
    "network.summary()\n",
    "\n",
    "# 自定义一个继承自keras.Model的自定义网络类\n",
    "\n",
    "class MyModel(tf.keras.Model):\n",
    "    # 自定义网络类，继承自Model基类\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        # 完成网络层内需要的网络层创建工作\n",
    "        self.fc1 = MyDense(28*28, 256)\n",
    "        self.fc2 = MyDense(256, 128)\n",
    "        self.fc3 = MyDense(128, 64)\n",
    "        self.fc4 = MyDense(64 ,32)\n",
    "        self.fc5 = MyDense(32, 10)\n",
    "        \n",
    "    # 实现向前计算逻辑\n",
    "    def call(self, inputs, training=None):\n",
    "        # 自定义向前计算逻辑\n",
    "        x = self.fc1(inputs)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "network_1 = MyModel()\n",
    "network_1.build(input_shape=(None, 28*28))\n",
    "network_1.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "URL fetch failure on https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5: None -- EOF occurred in violation of protocol (_ssl.c:748)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSSLEOFError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda2/envs/tf/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1317\u001b[0m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[0;32m-> 1318\u001b[0;31m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[0m\u001b[1;32m   1319\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1284\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1233\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1234\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    965\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1399\u001b[0m             self.sock = self._context.wrap_socket(self.sock,\n\u001b[0;32m-> 1400\u001b[0;31m                                                   server_hostname=server_hostname)\n\u001b[0m\u001b[1;32m   1401\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_hostname\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_hostname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    400\u001b[0m                          \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m                          _context=self, _session=session)\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sock, keyfile, certfile, server_side, cert_reqs, ssl_version, ca_certs, do_handshake_on_connect, family, type, proto, fileno, suppress_ragged_eofs, npn_protocols, ciphers, server_hostname, _context, _session)\u001b[0m\n\u001b[1;32m    807\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"do_handshake_on_connect should not be specified for non-blocking sockets\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1060\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1061\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1062\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    682\u001b[0m         \u001b[0;34m\"\"\"Start the SSL/TLS handshake.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    684\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_hostname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSSLEOFError\u001b[0m: EOF occurred in violation of protocol (_ssl.c:748)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda2/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget_file\u001b[0;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_progress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    543\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0;32m--> 544\u001b[0;31m                                   '_open', req)\n\u001b[0m\u001b[1;32m    545\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1360\u001b[0m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0;32m-> 1361\u001b[0;31m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[0m\u001b[1;32m   1362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mURLError\u001b[0m: <urlopen error EOF occurred in violation of protocol (_ssl.c:748)>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-308bba6fe34a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mresnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResNet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mresnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# 测试网络的输出\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/applications/resnet.py\u001b[0m in \u001b[0;36mResNet50\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m   return ResNet(stack_fn, False, True, 'resnet50', include_top, weights,\n\u001b[0;32m--> 463\u001b[0;31m                 input_tensor, input_shape, pooling, classes, **kwargs)\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/applications/resnet.py\u001b[0m in \u001b[0;36mResNet\u001b[0;34m(stack_fn, preact, use_bias, model_name, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mBASE_WEIGHTS_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mcache_subdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         file_hash=file_hash)\n\u001b[0m\u001b[1;32m    210\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget_file\u001b[0;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mURLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: URL fetch failure on https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5: None -- EOF occurred in violation of protocol (_ssl.c:748)"
     ]
    }
   ],
   "source": [
    "##########################################################################################\n",
    "# 模型乐园\n",
    "# 加载ImageNet预训练网络模型，并去掉最后一层\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, optimizers, losses, metrics, Sequential\n",
    "resnet = tf.keras.applications.ResNet50(weights='imagenet', include_top=False)\n",
    "resnet.summary()\n",
    "# 测试网络的输出\n",
    "x = tf.random.normal([4,224,224,3])\n",
    "out = resnet(x) # 获得子网络输出\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets: (60000, 28, 28) (60000,) 0 255\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  200960    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  32896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  2080      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  330       \n",
      "=================================================================\n",
      "Total params: 244,522\n",
      "Trainable params: 244,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0 loss: 2.3312695\n",
      "78 Evaluate Acc: 0.1179 0.1179\n",
      "100 loss: 0.5564696\n",
      "200 loss: 0.22996806\n",
      "300 loss: 0.21530548\n",
      "400 loss: 0.18380432\n",
      "500 loss: 0.15514481\n",
      "78 Evaluate Acc: 0.9456 0.9456\n",
      "600 loss: 0.1353615\n",
      "700 loss: 0.13158949\n",
      "800 loss: 0.13653512\n",
      "900 loss: 0.144175\n",
      "1000 loss: 0.10739037\n",
      "78 Evaluate Acc: 0.9618 0.9618\n",
      "1100 loss: 0.11779716\n",
      "1200 loss: 0.10983212\n",
      "1300 loss: 0.10370333\n",
      "1400 loss: 0.103829086\n",
      "1500 loss: 0.08235387\n",
      "78 Evaluate Acc: 0.9688 0.9688\n",
      "1600 loss: 0.092793256\n",
      "1700 loss: 0.09975317\n",
      "1800 loss: 0.0986121\n",
      "1900 loss: 0.09221369\n",
      "2000 loss: 0.09388699\n",
      "78 Evaluate Acc: 0.9703 0.9703\n",
      "2100 loss: 0.07570842\n",
      "2200 loss: 0.088935554\n",
      "2300 loss: 0.09855441\n",
      "2400 loss: 0.08360975\n",
      "2500 loss: 0.060147036\n",
      "78 Evaluate Acc: 0.9731 0.9731\n",
      "2600 loss: 0.07647397\n",
      "2700 loss: 0.08087273\n",
      "2800 loss: 0.08278128\n",
      "2900 loss: 0.0699462\n",
      "3000 loss: 0.084137894\n",
      "78 Evaluate Acc: 0.9716 0.9716\n",
      "3100 loss: 0.076464765\n",
      "3200 loss: 0.073505975\n"
     ]
    }
   ],
   "source": [
    "############################################################################################################\n",
    "# 测量工具\n",
    "import  tensorflow as tf\n",
    "from    tensorflow.keras import datasets, layers, optimizers, Sequential, metrics\n",
    "\n",
    "\n",
    "def preprocess(x, y):\n",
    "\n",
    "    x = tf.cast(x, dtype=tf.float32) / 255.\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "\n",
    "    return x,y\n",
    "\n",
    "\n",
    "batchsz = 128\n",
    "(x, y), (x_val, y_val) = datasets.mnist.load_data()\n",
    "print('datasets:', x.shape, y.shape, x.min(), x.max())\n",
    "\n",
    "\n",
    "\n",
    "db = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "db = db.map(preprocess).shuffle(60000).batch(batchsz).repeat(10)\n",
    "\n",
    "ds_val = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "ds_val = ds_val.map(preprocess).batch(batchsz)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "network = Sequential([layers.Dense(256, activation='relu'),\n",
    "                     layers.Dense(128, activation='relu'),\n",
    "                     layers.Dense(64, activation='relu'),\n",
    "                     layers.Dense(32, activation='relu'),\n",
    "                     layers.Dense(10)])\n",
    "network.build(input_shape=(None, 28*28))\n",
    "network.summary()\n",
    "\n",
    "optimizer = optimizers.Adam(lr=0.01)\n",
    "\n",
    "acc_meter = metrics.Accuracy()\n",
    "loss_meter = metrics.Mean()\n",
    "\n",
    "\n",
    "# 遍历当前数据集\n",
    "for step, (x,y) in enumerate(db):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        # [b, 28, 28] => [b, 784]\n",
    "        x = tf.reshape(x, (-1, 28*28))\n",
    "        # [b, 784] => [b, 10]\n",
    "        out = network(x)\n",
    "        # [b] => [b, 10]\n",
    "        y_onehot = tf.one_hot(y, depth=10)\n",
    "        # [b]\n",
    "        loss = tf.reduce_mean(tf.losses.categorical_crossentropy(y_onehot, out, from_logits=True))\n",
    "\n",
    "        loss_meter.update_state(loss)\n",
    "\n",
    "\n",
    "\n",
    "    grads = tape.gradient(loss, network.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, network.trainable_variables))\n",
    "\n",
    "\n",
    "    if step % 100 == 0:\n",
    "\n",
    "        print(step, 'loss:', loss_meter.result().numpy())\n",
    "        loss_meter.reset_states()\n",
    "\n",
    "\n",
    "    # evaluate\n",
    "    if step % 500 == 0:\n",
    "        total, total_correct = 0., 0\n",
    "        acc_meter.reset_states()\n",
    "\n",
    "        for step, (x, y) in enumerate(ds_val):\n",
    "            # [b, 28, 28] => [b, 784]\n",
    "            x = tf.reshape(x, (-1, 28*28))\n",
    "            # [b, 784] => [b, 10]\n",
    "            out = network(x)\n",
    "\n",
    "\n",
    "            # [b, 10] => [b]\n",
    "            pred = tf.argmax(out, axis=1)\n",
    "            pred = tf.cast(pred, dtype=tf.int32)\n",
    "            # bool type\n",
    "            correct = tf.equal(pred, y)\n",
    "            # bool tensor => int tensor => numpy\n",
    "            total_correct += tf.reduce_sum(tf.cast(correct, dtype=tf.int32)).numpy()\n",
    "            total += x.shape[0]\n",
    "\n",
    "            acc_meter.update_state(y, pred)\n",
    "\n",
    "\n",
    "        print(step, 'Evaluate Acc:', total_correct/total, acc_meter.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
